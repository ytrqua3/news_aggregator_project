{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# news_aggregator_training\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Startup cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set environment variables for sagemaker_studio imports\n\nimport os\nos.environ['DataZoneProjectId'] = 'btceu4s17ranu1'\nos.environ['DataZoneDomainId'] = 'dzd-4kbjtzjqm94pk9'\nos.environ['DataZoneEnvironmentId'] = '4jlwpldxvx9d49'\nos.environ['DataZoneDomainRegion'] = 'us-east-2'\n\n# create both a function and variable for metadata access\n_resource_metadata = None\n\ndef _get_resource_metadata():\n    global _resource_metadata\n    if _resource_metadata is None:\n        _resource_metadata = {\n            \"AdditionalMetadata\": {\n                \"DataZoneProjectId\": \"btceu4s17ranu1\",\n                \"DataZoneDomainId\": \"dzd-4kbjtzjqm94pk9\",\n                \"DataZoneEnvironmentId\": \"4jlwpldxvx9d49\",\n                \"DataZoneDomainRegion\": \"us-east-2\",\n            }\n        }\n    return _resource_metadata\nmetadata = _get_resource_metadata()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nLogging Configuration\n\nPurpose:\n--------\nThis sets up the logging framework for code executed in the user namespace.\n\"\"\"\n\nfrom typing import Optional\n\n\ndef _set_logging(log_dir: str, log_file: str, log_name: Optional[str] = None):\n    import os\n    import logging\n    from logging.handlers import RotatingFileHandler\n\n    level = logging.INFO\n    max_bytes = 5 * 1024 * 1024\n    backup_count = 5\n\n    # fallback to /tmp dir on access, helpful for local dev setup\n    try:\n        os.makedirs(log_dir, exist_ok=True)\n    except Exception:\n        log_dir = \"/tmp/kernels/\"\n\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger() if not log_name else logging.getLogger(log_name)\n    logger.handlers = []\n    logger.setLevel(level)\n\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # Rotating file handler\n    fh = RotatingFileHandler(filename=log_path, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\")\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    logger.info(f\"Logging initialized for {log_name}.\")\n\n\n_set_logging(\"/var/log/computeEnvironments/kernel/\", \"kernel.log\")\n_set_logging(\"/var/log/studio/data-notebook-kernel-server/\", \"metrics.log\", \"metrics\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import logging\nfrom sagemaker_studio import ClientConfig, sqlutils, sparkutils, dataframeutils\n\nlogger = logging.getLogger(__name__)\nlogger.info(\"Initializing sparkutils\")\nspark = sparkutils.init()\nlogger.info(\"Finished initializing sparkutils\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def _reset_os_path():\n    \"\"\"\n    Reset the process's working directory to handle mount timing issues.\n    \n    This function resolves a race condition where the Python process starts\n    before the filesystem mount is complete, causing the process to reference\n    old mount paths and inodes. By explicitly changing to the mounted directory\n    (/home/sagemaker-user), we ensure the process uses the correct, up-to-date\n    mount point.\n    \n    The function logs stat information (device ID and inode) before and after\n    the directory change to verify that the working directory is properly\n    updated to reference the new mount.\n    \n    Note:\n        This is executed at module import time to ensure the fix is applied\n        as early as possible in the kernel initialization process.\n    \"\"\"\n    try:\n        import os\n        import logging\n\n        logger = logging.getLogger(__name__)\n        logger.info(\"---------Before------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n\n        os.chdir(\"/home/sagemaker-user\")\n\n        logger.info(\"---------After------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n    except Exception as e:\n        logger.exception(f\"Failed to reset working directory: {e}\")\n\n_reset_os_path()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Notebook"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import torch\r\nimport sagemaker\r\nimport transformers\r\nfrom sagemaker.huggingface import HuggingFace",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Fetched defaults config from location: /etc/xdg/sagemaker/config.yaml\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/sagemaker_packages/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        },
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "role = sagemaker.get_execution_role()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "sagemaker_session = sagemaker.Session()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "estimator = HuggingFace(\r\n    entry_point='script.py',\r\n    source_dir='./',\r\n    role=role,\r\n    instance_count=1,\r\n    instance_type=\"ml.g4dn.xlarge\",\r\n    transformers_version='4.56',\r\n    pytorch_version='2.8',\r\n    output_path='s3://news-aggregator-sadrian-bucket/models/',\r\n    py_version='py312',\r\n    hyperparameters={\r\n        'epochs': 2,\r\n        'train_batch_size': 8,\r\n        'valid_batch_size': 16,\r\n        'learning_rate': 3e-05,\r\n        'seq_max_len': 256\r\n    },\r\n    enable_sagemaker_metrics=True\r\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        },
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "estimator.fit()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2026-01-31 08:34:51 Starting - Starting the training job\n2026-01-31 08:34:51 Pending - Training job waiting for capacity."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 08:35:14 Pending - Preparing the instances for training."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 08:35:38 Downloading - Downloading input data."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 08:35:59 Downloading - Downloading the training image."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 08:42:23 Training - Training image download completed. Training in progress.."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n\u001b[34mbash: no job control in this shell\u001b[0m\n\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 575.57.08\u001b[0m\n\u001b[34mCurrent installed NVIDIA driver version is 570.195.03\u001b[0m\n\u001b[34mAdding CUDA compat to LD_LIBRARY_PATH\u001b[0m\n\u001b[34m/usr/local/cuda/compat:/usr/local/cuda/compat:/usr/local/lib:/opt/amazon/ofi-nccl/lib/x86_64-linux-gnu:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:/usr/local/lib:/usr/local/cuda/lib64:/opt/amazon/ofi-nccl/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/lib64\u001b[0m\n\u001b[34m2026-01-31 08:42:28,917 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n\u001b[34m2026-01-31 08:42:28,936 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 08:42:28,958 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n\u001b[34m2026-01-31 08:42:28,961 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n\u001b[34m2026-01-31 08:42:30,297 sagemaker-training-toolkit INFO     Provided path: /opt/ml/code  is empty, unzipping\u001b[0m\n\u001b[34m2026-01-31 08:42:31,466 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 08:42:31,496 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 08:42:31,526 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 08:42:31,536 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n\u001b[34mTraining Env:\u001b[0m\n\u001b[34m{\n    \"additional_framework_parameters\": {},\n    \"channel_input_dirs\": {},\n    \"current_host\": \"algo-1\",\n    \"current_instance_group\": \"homogeneousCluster\",\n    \"current_instance_group_hosts\": [\n        \"algo-1\"\n    ],\n    \"current_instance_type\": \"ml.g4dn.xlarge\",\n    \"distribution_hosts\": [],\n    \"distribution_instance_groups\": [],\n    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n    \"hosts\": [\n        \"algo-1\"\n    ],\n    \"hyperparameters\": {\n        \"epochs\": 2,\n        \"learning_rate\": 3e-05,\n        \"seq_max_len\": 256,\n        \"train_batch_size\": 8,\n        \"valid_batch_size\": 16\n    },\n    \"input_config_dir\": \"/opt/ml/input/config\",\n    \"input_data_config\": {},\n    \"input_dir\": \"/opt/ml/input\",\n    \"instance_groups\": [\n        \"homogeneousCluster\"\n    ],\n    \"instance_groups_dict\": {\n        \"homogeneousCluster\": {\n            \"instance_group_name\": \"homogeneousCluster\",\n            \"instance_type\": \"ml.g4dn.xlarge\",\n            \"hosts\": [\n                \"algo-1\"\n            ]\n        }\n    },\n    \"is_hetero\": false,\n    \"is_master\": true,\n    \"is_modelparallel_enabled\": null,\n    \"is_smddpmprun_installed\": false,\n    \"is_smddprun_installed\": false,\n    \"job_name\": \"huggingface-pytorch-training-2026-01-31-08-34-13-056\",\n    \"log_level\": 20,\n    \"master_hostname\": \"algo-1\",\n    \"model_dir\": \"/opt/ml/model\",\n    \"module_dir\": \"s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-08-34-13-056/source/sourcedir.tar.gz\",\n    \"module_name\": \"script\",\n    \"network_interface_name\": \"eth0\",\n    \"num_cpus\": 4,\n    \"num_gpus\": 1,\n    \"num_neurons\": 0,\n    \"output_data_dir\": \"/opt/ml/output/data\",\n    \"output_dir\": \"/opt/ml/output\",\n    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n    \"resource_config\": {\n        \"current_host\": \"algo-1\",\n        \"current_instance_type\": \"ml.g4dn.xlarge\",\n        \"current_group_name\": \"homogeneousCluster\",\n        \"hosts\": [\n            \"algo-1\"\n        ],\n        \"instance_groups\": [\n            {\n                \"instance_group_name\": \"homogeneousCluster\",\n                \"instance_type\": \"ml.g4dn.xlarge\",\n                \"hosts\": [\n                    \"algo-1\"\n                ]\n            }\n        ],\n        \"network_interface_name\": \"eth0\",\n        \"topology\": null\n    },\n    \"topology\": null,\n    \"user_entry_point\": \"script.py\"\u001b[0m\n\u001b[34m}\u001b[0m\n\u001b[34mEnvironment variables:\u001b[0m\n\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n\u001b[34mSM_HPS={\"epochs\":2,\"learning_rate\":3e-05,\"seq_max_len\":256,\"train_batch_size\":8,\"valid_batch_size\":16}\u001b[0m\n\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n\u001b[34mSM_CHANNELS=[]\u001b[0m\n\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n\u001b[34mSM_IS_HETERO=false\u001b[0m\n\u001b[34mSM_MODULE_NAME=script\u001b[0m\n\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n\u001b[34mSM_NUM_CPUS=4\u001b[0m\n\u001b[34mSM_NUM_GPUS=1\u001b[0m\n\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n\u001b[34mSM_MODULE_DIR=s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-08-34-13-056/source/sourcedir.tar.gz\u001b[0m\n\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":2,\"learning_rate\":3e-05,\"seq_max_len\":256,\"train_batch_size\":8,\"valid_batch_size\":16},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"huggingface-pytorch-training-2026-01-31-08-34-13-056\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-08-34-13-056/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"topology\":null,\"user_entry_point\":\"script.py\"}\u001b[0m\n\u001b[34mSM_USER_ARGS=[\"--epochs\",\"2\",\"--learning_rate\",\"3e-05\",\"--seq_max_len\",\"256\",\"--train_batch_size\",\"8\",\"--valid_batch_size\",\"16\"]\u001b[0m\n\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n\u001b[34mSM_HP_LEARNING_RATE=3e-05\u001b[0m\n\u001b[34mSM_HP_SEQ_MAX_LEN=256\u001b[0m\n\u001b[34mSM_HP_TRAIN_BATCH_SIZE=8\u001b[0m\n\u001b[34mSM_HP_VALID_BATCH_SIZE=16\u001b[0m\n\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python312.zip:/usr/local/lib/python3.12:/usr/local/lib/python3.12/lib-dynload:/usr/local/lib/python3.12/site-packages\u001b[0m\n\u001b[34mInvoking script with the following command:\u001b[0m\n\u001b[34m/usr/local/bin/python script.py --epochs 2 --learning_rate 3e-05 --seq_max_len 256 --train_batch_size 8 --valid_batch_size 16\u001b[0m\n\u001b[34m2026-01-31 08:42:31,537 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n\u001b[34m2026-01-31 08:42:31,537 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mstart script.py\u001b[0m\n\u001b[34mtrain test split performed\u001b[0m\n\u001b[34mFull dataset:(422419, 2)\u001b[0m\n\u001b[34mtrain dataset:(337935, 2)\u001b[0m\n\u001b[34mvalidaiton dataset:(84484, 2)\u001b[0m\n\u001b[34mSuccessfully labelled data\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mdata loaders created successfully\u001b[0m\n\u001b[34mStarting training process\u001b[0m\n\u001b[34mstarting Epoch 0...\u001b[0m\n\u001b[34mTraining loss: 1.379422903060913\u001b[0m\n\u001b[34mTraining Accuracy: 0.25\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.34724444523279124\u001b[0m\n\u001b[34mTraining Accuracy: 0.8975204959008198\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.3043999723053315\u001b[0m\n\u001b[34mTraining Accuracy: 0.9137086291370863\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.28034263116651315\u001b[0m\n\u001b[34mTraining Accuracy: 0.9214219052063196\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.26461724570024536\u001b[0m\n\u001b[34mTraining Accuracy: 0.926522423878806\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.2534732036381933\u001b[0m\n\u001b[34mTraining Accuracy: 0.9304027838886445\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.24520456982691113\u001b[0m\n\u001b[34mTraining Accuracy: 0.9331563947868404\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.23845821103507697\u001b[0m\n\u001b[34mTraining Accuracy: 0.9354875574983572\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.23222046462355272\u001b[0m\n\u001b[34mTraining Accuracy: 0.9374234394140146\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mEpoch 0 Training loss: 0.22934037877846197\u001b[0m\n\u001b[34mEpoch 0 Training Accuracy: 0.9382810303756639\u001b[0m\n\u001b[34mValidation loss: 0.023164115846157074\u001b[0m\n\u001b[34mValidation Accuracy: 1.0\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.22092097906297986\u001b[0m\n\u001b[34mValidation Accuracy: 0.9483641358641358\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.21438807112395022\u001b[0m\n\u001b[34mValidation Accuracy: 0.9512743628185907\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.21647565687453366\u001b[0m\n\u001b[34mValidation Accuracy: 0.9508913695434855\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.2129951346441501\u001b[0m\n\u001b[34mValidation Accuracy: 0.9510122469382655\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.21147583359973715\u001b[0m\n\u001b[34mValidation Accuracy: 0.9514722055588882\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mEpoch 0 Validation loss: 0.20851799149994496\u001b[0m\n\u001b[34mEpoch 0 Validation Accuracy: 0.9522158041759387\u001b[0m\n\u001b[34mstarting Epoch 1...\u001b[0m\n\u001b[34mTraining loss: 0.5670244693756104\u001b[0m\n\u001b[34mTraining Accuracy: 0.875\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.14690606354755775\u001b[0m\n\u001b[34mTraining Accuracy: 0.9643321335732853\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15156864478660526\u001b[0m\n\u001b[34mTraining Accuracy: 0.9626037396260374\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15228880560099772\u001b[0m\n\u001b[34mTraining Accuracy: 0.9626941537230851\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15330176664198963\u001b[0m\n\u001b[34mTraining Accuracy: 0.9622768861556922\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.1541592426778514\u001b[0m\n\u001b[34mTraining Accuracy: 0.9621415143394264\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15383933485560594\u001b[0m\n\u001b[34mTraining Accuracy: 0.9621595946801773\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15415310622334638\u001b[0m\n\u001b[34mTraining Accuracy: 0.9622725064998143\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mTraining loss: 0.15517101290908425\u001b[0m\n\u001b[34mTraining Accuracy: 0.9621384465388365\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mEpoch 1 Training loss: 0.15547880318052817\u001b[0m\n\u001b[34mEpoch 1 Training Accuracy: 0.9620400372852768\u001b[0m\n\u001b[34mValidation loss: 0.0054789381101727486\u001b[0m\n\u001b[34mValidation Accuracy: 1.0\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.201112313610938\u001b[0m\n\u001b[34mValidation Accuracy: 0.9551073926073926\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.19454104801328578\u001b[0m\n\u001b[34mValidation Accuracy: 0.9566779110444777\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.19697986367471698\u001b[0m\n\u001b[34mValidation Accuracy: 0.9556189603465511\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.1927970749334921\u001b[0m\n\u001b[34mValidation Accuracy: 0.9556829542614347\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mValidation loss: 0.19146204434053612\u001b[0m\n\u001b[34mValidation Accuracy: 0.9564337132573485\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mEpoch 1 Validation loss: 0.1888559997648343\u001b[0m\n\u001b[34mEpoch 1 Validation Accuracy: 0.9571043037734955\u001b[0m\n\u001b[34mmodel successfully trained\u001b[0m\n\u001b[34msaving model into s3\u001b[0m\n\u001b[34msucessfully ended script.py\u001b[0m\n\u001b[34m2026-01-31 12:55:12,793 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n\u001b[34m2026-01-31 12:55:12,793 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n\u001b[34m2026-01-31 12:55:12,794 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 12:55:35 Uploading - Uploading generated training model\n2026-01-31 12:55:35 Completed - Training job completed\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training seconds: 15596\nBillable seconds: 15596\n"
        },
        {
          "output_type": "display_data",
          "data": {},
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Shutdown cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nStop spark session and associated Athena Spark session\n\"\"\"\n\nfrom IPython import get_ipython as _get_ipython\n_get_ipython().user_ns[\"spark\"].stop()",
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}