{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# news_aggregator_deployment\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Startup cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set environment variables for sagemaker_studio imports\n\nimport os\nos.environ['DataZoneProjectId'] = 'btceu4s17ranu1'\nos.environ['DataZoneDomainId'] = 'dzd-4kbjtzjqm94pk9'\nos.environ['DataZoneEnvironmentId'] = '4jlwpldxvx9d49'\nos.environ['DataZoneDomainRegion'] = 'us-east-2'\n\n# create both a function and variable for metadata access\n_resource_metadata = None\n\ndef _get_resource_metadata():\n    global _resource_metadata\n    if _resource_metadata is None:\n        _resource_metadata = {\n            \"AdditionalMetadata\": {\n                \"DataZoneProjectId\": \"btceu4s17ranu1\",\n                \"DataZoneDomainId\": \"dzd-4kbjtzjqm94pk9\",\n                \"DataZoneEnvironmentId\": \"4jlwpldxvx9d49\",\n                \"DataZoneDomainRegion\": \"us-east-2\",\n            }\n        }\n    return _resource_metadata\nmetadata = _get_resource_metadata()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nLogging Configuration\n\nPurpose:\n--------\nThis sets up the logging framework for code executed in the user namespace.\n\"\"\"\n\nfrom typing import Optional\n\n\ndef _set_logging(log_dir: str, log_file: str, log_name: Optional[str] = None):\n    import os\n    import logging\n    from logging.handlers import RotatingFileHandler\n\n    level = logging.INFO\n    max_bytes = 5 * 1024 * 1024\n    backup_count = 5\n\n    # fallback to /tmp dir on access, helpful for local dev setup\n    try:\n        os.makedirs(log_dir, exist_ok=True)\n    except Exception:\n        log_dir = \"/tmp/kernels/\"\n\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger() if not log_name else logging.getLogger(log_name)\n    logger.handlers = []\n    logger.setLevel(level)\n\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # Rotating file handler\n    fh = RotatingFileHandler(filename=log_path, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\")\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    logger.info(f\"Logging initialized for {log_name}.\")\n\n\n_set_logging(\"/var/log/computeEnvironments/kernel/\", \"kernel.log\")\n_set_logging(\"/var/log/studio/data-notebook-kernel-server/\", \"metrics.log\", \"metrics\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import logging\nfrom sagemaker_studio import ClientConfig, sqlutils, sparkutils, dataframeutils\n\nlogger = logging.getLogger(__name__)\nlogger.info(\"Initializing sparkutils\")\nspark = sparkutils.init()\nlogger.info(\"Finished initializing sparkutils\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def _reset_os_path():\n    \"\"\"\n    Reset the process's working directory to handle mount timing issues.\n    \n    This function resolves a race condition where the Python process starts\n    before the filesystem mount is complete, causing the process to reference\n    old mount paths and inodes. By explicitly changing to the mounted directory\n    (/home/sagemaker-user), we ensure the process uses the correct, up-to-date\n    mount point.\n    \n    The function logs stat information (device ID and inode) before and after\n    the directory change to verify that the working directory is properly\n    updated to reference the new mount.\n    \n    Note:\n        This is executed at module import time to ensure the fix is applied\n        as early as possible in the kernel initialization process.\n    \"\"\"\n    try:\n        import os\n        import logging\n\n        logger = logging.getLogger(__name__)\n        logger.info(\"---------Before------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n\n        os.chdir(\"/home/sagemaker-user\")\n\n        logger.info(\"---------After------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n    except Exception as e:\n        logger.exception(f\"Failed to reset working directory: {e}\")\n\n_reset_os_path()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Notebook"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from sagemaker.huggingface import HuggingFaceModel\r\nfrom sagemaker import get_execution_role\r\n\r\nrole = get_execution_role()\r\n\r\nmodel_s3_path = 's3://news-aggregator-sadrian-bucket/models/huggingface-pytorch-training-2026-01-31-02-42-49-514/output/model.tar.gz'\r\n\r\npredictor = HuggingFaceModel(\r\n    model_data=model_s3_path,\r\n    role=role,\r\n    transformers_version=\"4.51\",\r\n    py_version=\"py312\",\r\n    pytorch_version=\"2.6\",\r\n    entry_point='inference_test.py'\r\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "predictor = predictor.deploy(\r\n    initial_instance_count=1,\r\n    instance_type='ml.c5.xlarge',\r\n    endpoint_name='news-aggregator-smoke-test-v2'\r\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "!"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "predictor.predict({'input': [1,2,3,4,5,6,7,8,9,1]})",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "['{\"label\": 0, \"probabilities\": [[0.9915100336074829, 0.008489933796226978]]}',\n 'application/json']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Shutdown cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nStop spark session and associated Athena Spark session\n\"\"\"\n\nfrom IPython import get_ipython as _get_ipython\n_get_ipython().user_ns[\"spark\"].stop()",
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}