{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# news_aggregator_training\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Startup cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Set environment variables for sagemaker_studio imports\n\nimport os\nos.environ['DataZoneProjectId'] = 'btceu4s17ranu1'\nos.environ['DataZoneDomainId'] = 'dzd-4kbjtzjqm94pk9'\nos.environ['DataZoneEnvironmentId'] = '4jlwpldxvx9d49'\nos.environ['DataZoneDomainRegion'] = 'us-east-2'\n\n# create both a function and variable for metadata access\n_resource_metadata = None\n\ndef _get_resource_metadata():\n    global _resource_metadata\n    if _resource_metadata is None:\n        _resource_metadata = {\n            \"AdditionalMetadata\": {\n                \"DataZoneProjectId\": \"btceu4s17ranu1\",\n                \"DataZoneDomainId\": \"dzd-4kbjtzjqm94pk9\",\n                \"DataZoneEnvironmentId\": \"4jlwpldxvx9d49\",\n                \"DataZoneDomainRegion\": \"us-east-2\",\n            }\n        }\n    return _resource_metadata\nmetadata = _get_resource_metadata()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nLogging Configuration\n\nPurpose:\n--------\nThis sets up the logging framework for code executed in the user namespace.\n\"\"\"\n\nfrom typing import Optional\n\n\ndef _set_logging(log_dir: str, log_file: str, log_name: Optional[str] = None):\n    import os\n    import logging\n    from logging.handlers import RotatingFileHandler\n\n    level = logging.INFO\n    max_bytes = 5 * 1024 * 1024\n    backup_count = 5\n\n    # fallback to /tmp dir on access, helpful for local dev setup\n    try:\n        os.makedirs(log_dir, exist_ok=True)\n    except Exception:\n        log_dir = \"/tmp/kernels/\"\n\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n\n    logger = logging.getLogger() if not log_name else logging.getLogger(log_name)\n    logger.handlers = []\n    logger.setLevel(level)\n\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # Rotating file handler\n    fh = RotatingFileHandler(filename=log_path, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\")\n    fh.setFormatter(formatter)\n    logger.addHandler(fh)\n\n    logger.info(f\"Logging initialized for {log_name}.\")\n\n\n_set_logging(\"/var/log/computeEnvironments/kernel/\", \"kernel.log\")\n_set_logging(\"/var/log/studio/data-notebook-kernel-server/\", \"metrics.log\", \"metrics\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import logging\nfrom sagemaker_studio import ClientConfig, sqlutils, sparkutils, dataframeutils\n\nlogger = logging.getLogger(__name__)\nlogger.info(\"Initializing sparkutils\")\nspark = sparkutils.init()\nlogger.info(\"Finished initializing sparkutils\")",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def _reset_os_path():\n    \"\"\"\n    Reset the process's working directory to handle mount timing issues.\n    \n    This function resolves a race condition where the Python process starts\n    before the filesystem mount is complete, causing the process to reference\n    old mount paths and inodes. By explicitly changing to the mounted directory\n    (/home/sagemaker-user), we ensure the process uses the correct, up-to-date\n    mount point.\n    \n    The function logs stat information (device ID and inode) before and after\n    the directory change to verify that the working directory is properly\n    updated to reference the new mount.\n    \n    Note:\n        This is executed at module import time to ensure the fix is applied\n        as early as possible in the kernel initialization process.\n    \"\"\"\n    try:\n        import os\n        import logging\n\n        logger = logging.getLogger(__name__)\n        logger.info(\"---------Before------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n\n        os.chdir(\"/home/sagemaker-user\")\n\n        logger.info(\"---------After------\")\n        logger.info(\"CWD: %s\", os.getcwd())\n        logger.info(\"stat('.'): %s %s\", os.stat('.').st_dev, os.stat('.').st_ino)\n        logger.info(\"stat('/home/sagemaker-user'): %s %s\", os.stat('/home/sagemaker-user').st_dev, os.stat('/home/sagemaker-user').st_ino)\n    except Exception as e:\n        logger.exception(f\"Failed to reset working directory: {e}\")\n\n_reset_os_path()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Notebook"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import torch\r\nimport sagemaker\r\nimport transformers\r\nfrom sagemaker.huggingface import HuggingFace",
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "role = sagemaker.get_execution_role()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "sagemaker_session = sagemaker.Session()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "estimator = HuggingFace(\r\n    entry_point='test.py',\r\n    source_dir='./',\r\n    role=role,\r\n    instance_count=1,\r\n    instance_type=\"ml.g4dn.xlarge\",\r\n    transformers_version='4.56',\r\n    pytorch_version='2.8',\r\n    output_path='s3://news-aggregator-sadrian-bucket/models/',\r\n    py_version='py312',\r\n    hyperparameters={\r\n        'epochs': 1,\r\n        'train_batch_size': 2,\r\n        'valid_batch_size': 1,\r\n        'learning_rate': 1e-05,\r\n        'seq_max_len': 32\r\n    },\r\n    enable_sagemaker_metrics=True\r\n)",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3Bucket\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sagemaker.config INFO - Applied value from config key = SageMaker.PythonSDK.Modules.Session.DefaultS3ObjectKeyPrefix\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "estimator.fit()",
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2026-01-31 02:43:29 Starting - Starting the training job\n2026-01-31 02:43:29 Pending - Training job waiting for capacity."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 02:43:42 Pending - Preparing the instances for training."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 02:44:27 Downloading - Downloading the training image."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 02:50:51 Training - Training image download completed. Training in progress.."
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n\u001b[34mbash: no job control in this shell\u001b[0m\n\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 575.57.08\u001b[0m\n\u001b[34mCurrent installed NVIDIA driver version is 570.195.03\u001b[0m\n\u001b[34mAdding CUDA compat to LD_LIBRARY_PATH\u001b[0m\n\u001b[34m/usr/local/cuda/compat:/usr/local/cuda/compat:/usr/local/lib:/opt/amazon/ofi-nccl/lib/x86_64-linux-gnu:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:/usr/local/lib:/usr/local/cuda/lib64:/opt/amazon/ofi-nccl/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/lib64\u001b[0m\n\u001b[34m2026-01-31 02:51:02,036 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n\u001b[34m2026-01-31 02:51:02,056 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 02:51:02,080 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n\u001b[34m2026-01-31 02:51:02,084 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n\u001b[34m2026-01-31 02:51:03,473 sagemaker-training-toolkit INFO     Provided path: /opt/ml/code  is empty, unzipping\u001b[0m\n\u001b[34m2026-01-31 02:51:04,677 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 02:51:04,710 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 02:51:04,742 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n\u001b[34m2026-01-31 02:51:04,753 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n\u001b[34mTraining Env:\u001b[0m\n\u001b[34m{\n    \"additional_framework_parameters\": {},\n    \"channel_input_dirs\": {},\n    \"current_host\": \"algo-1\",\n    \"current_instance_group\": \"homogeneousCluster\",\n    \"current_instance_group_hosts\": [\n        \"algo-1\"\n    ],\n    \"current_instance_type\": \"ml.g4dn.xlarge\",\n    \"distribution_hosts\": [],\n    \"distribution_instance_groups\": [],\n    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n    \"hosts\": [\n        \"algo-1\"\n    ],\n    \"hyperparameters\": {\n        \"epochs\": 1,\n        \"learning_rate\": 1e-05,\n        \"seq_max_len\": 32,\n        \"train_batch_size\": 2,\n        \"valid_batch_size\": 1\n    },\n    \"input_config_dir\": \"/opt/ml/input/config\",\n    \"input_data_config\": {},\n    \"input_dir\": \"/opt/ml/input\",\n    \"instance_groups\": [\n        \"homogeneousCluster\"\n    ],\n    \"instance_groups_dict\": {\n        \"homogeneousCluster\": {\n            \"instance_group_name\": \"homogeneousCluster\",\n            \"instance_type\": \"ml.g4dn.xlarge\",\n            \"hosts\": [\n                \"algo-1\"\n            ]\n        }\n    },\n    \"is_hetero\": false,\n    \"is_master\": true,\n    \"is_modelparallel_enabled\": null,\n    \"is_smddpmprun_installed\": false,\n    \"is_smddprun_installed\": false,\n    \"job_name\": \"huggingface-pytorch-training-2026-01-31-02-42-49-514\",\n    \"log_level\": 20,\n    \"master_hostname\": \"algo-1\",\n    \"model_dir\": \"/opt/ml/model\",\n    \"module_dir\": \"s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-02-42-49-514/source/sourcedir.tar.gz\",\n    \"module_name\": \"test\",\n    \"network_interface_name\": \"eth0\",\n    \"num_cpus\": 4,\n    \"num_gpus\": 1,\n    \"num_neurons\": 0,\n    \"output_data_dir\": \"/opt/ml/output/data\",\n    \"output_dir\": \"/opt/ml/output\",\n    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n    \"resource_config\": {\n        \"current_host\": \"algo-1\",\n        \"current_instance_type\": \"ml.g4dn.xlarge\",\n        \"current_group_name\": \"homogeneousCluster\",\n        \"hosts\": [\n            \"algo-1\"\n        ],\n        \"instance_groups\": [\n            {\n                \"instance_group_name\": \"homogeneousCluster\",\n                \"instance_type\": \"ml.g4dn.xlarge\",\n                \"hosts\": [\n                    \"algo-1\"\n                ]\n            }\n        ],\n        \"network_interface_name\": \"eth0\",\n        \"topology\": null\n    },\n    \"topology\": null,\n    \"user_entry_point\": \"test.py\"\u001b[0m\n\u001b[34m}\u001b[0m\n\u001b[34mEnvironment variables:\u001b[0m\n\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n\u001b[34mSM_HPS={\"epochs\":1,\"learning_rate\":1e-05,\"seq_max_len\":32,\"train_batch_size\":2,\"valid_batch_size\":1}\u001b[0m\n\u001b[34mSM_USER_ENTRY_POINT=test.py\u001b[0m\n\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n\u001b[34mSM_CHANNELS=[]\u001b[0m\n\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.xlarge\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}}\u001b[0m\n\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n\u001b[34mSM_IS_HETERO=false\u001b[0m\n\u001b[34mSM_MODULE_NAME=test\u001b[0m\n\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n\u001b[34mSM_NUM_CPUS=4\u001b[0m\n\u001b[34mSM_NUM_GPUS=1\u001b[0m\n\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n\u001b[34mSM_MODULE_DIR=s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-02-42-49-514/source/sourcedir.tar.gz\u001b[0m\n\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"learning_rate\":1e-05,\"seq_max_len\":32,\"train_batch_size\":2,\"valid_batch_size\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"huggingface-pytorch-training-2026-01-31-02-42-49-514\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://news-aggregator-sadrian-bucket/huggingface-pytorch-training-2026-01-31-02-42-49-514/source/sourcedir.tar.gz\",\"module_name\":\"test\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"topology\":null,\"user_entry_point\":\"test.py\"}\u001b[0m\n\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--learning_rate\",\"1e-05\",\"--seq_max_len\",\"32\",\"--train_batch_size\",\"2\",\"--valid_batch_size\",\"1\"]\u001b[0m\n\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n\u001b[34mSM_HP_LEARNING_RATE=1e-05\u001b[0m\n\u001b[34mSM_HP_SEQ_MAX_LEN=32\u001b[0m\n\u001b[34mSM_HP_TRAIN_BATCH_SIZE=2\u001b[0m\n\u001b[34mSM_HP_VALID_BATCH_SIZE=1\u001b[0m\n\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python312.zip:/usr/local/lib/python3.12:/usr/local/lib/python3.12/lib-dynload:/usr/local/lib/python3.12/site-packages\u001b[0m\n\u001b[34mInvoking script with the following command:\u001b[0m\n\u001b[34m/usr/local/bin/python test.py --epochs 1 --learning_rate 1e-05 --seq_max_len 32 --train_batch_size 2 --valid_batch_size 1\u001b[0m\n\u001b[34m2026-01-31 02:51:04,753 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n\u001b[34m2026-01-31 02:51:04,754 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[34müöÄstart script.py\u001b[0m\n\u001b[34mepochs: 1, train_batch_size2, valid_batch_size: 1, learning_rate: 1e-05, data_path: news-aggregator-sadrian-bucket/newsCorpora.csv, seq_max_len: 32\u001b[0m\n\u001b[34müîç Environment check\u001b[0m\n\u001b[34mSM_MODEL_DIR: /opt/ml/model\u001b[0m\n\u001b[34mSM_OUTPUT_DATA_DIR: /opt/ml/output/data\u001b[0m\n\u001b[34müî• PyTorch version: 2.8.0+cu129\u001b[0m\n\u001b[34mCUDA available: True\u001b[0m\n\u001b[34müß™Starting dummy training process\u001b[0m\n\u001b[34mstarting Epoch 0...\u001b[0m\n\u001b[34mEpoch 1/1 - loss: 0.2468\u001b[0m\n\u001b[34mmodel successfully trained\u001b[0m\n\u001b[34msaving model into s3\u001b[0m\n\u001b[34m‚úÖ Model saved to /opt/ml/model/smoke_test.bin\u001b[0m\n\u001b[34müéâ test.py completed successfully\u001b[0m\n\u001b[34m2026-01-31 02:51:10,868 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n\u001b[34m2026-01-31 02:51:10,868 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n\u001b[34m2026-01-31 02:51:10,868 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n2026-01-31 02:51:29 Uploading - Uploading generated training model\n2026-01-31 02:51:29 Completed - Training job completed\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training seconds: 442\nBillable seconds: 442\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Shutdown cells"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "\"\"\"\nStop spark session and associated Athena Spark session\n\"\"\"\n\nfrom IPython import get_ipython as _get_ipython\n_get_ipython().user_ns[\"spark\"].stop()",
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}